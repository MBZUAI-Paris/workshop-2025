<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.ico"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="MBZUAI Workshop 2025: Foundations and Advances in Generative AI: Theory and Methods">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="MBZUAI, Workshop, AI">
    <title>MBZUAI Workshop 2025: Foundations and Advances in Generative AI: Theory and Methods</title>
</head>

<body>

    <div class="banner">
        <img src="assets/banner.jpg" alt="MBZUAI Workshop 2025: Foundations and Advances in Generative AI: Theory and Methods">
        <div class="top-left">
            <span class="title2">MBZUAI Workshop 2025:</span><br><br><br>
            <span class="title3">Foundations and Advances in Generative AI:<br><br>Theory and Methods</span>
            <!-- <span class="year">2025</span> -->
        </div>
        <div class="bottom-right">
            February 12-13, 2025<br>Paris, France
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href=".">Home</a>
            </td>
            <!-- <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td> -->
            <td class="navigation">
                <a title="Speaker List" href="speaker-list">Speaker List</a>
            </td>
            <td class="navigation">
                <a title="Conference Program" href="program-day-1">Program Day 1</a> 
            </td>
            <td class="navigation">
                <a title="Conference Program" href="program-day-2">Program Day 2</a> 
            </td>
            <!-- <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td> -->
            <!-- <td class="navigation">
                <a title="Conference Flyer" href="flyer">Flyer</a>
            </td> -->
        </tr>
    </table>

    <h2>Program on Wednesday, February 12</h2>

    <table>
        <tr>
            <td class="date" rowspan="2">
                9:00am
            </td>
            <td class="title-special">
                Registration and Coffee &amp; Tea!
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                9:30am
            </td>
            <td class="title">
                Factuality Challenges in the Era of Large Language Models: Can we Keep LLMs Safe and Factual? 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://mbzuai.ac.ae/study/faculty/preslav-nakov/">Preslav Nakov</a> (MBZUAI)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                We will discuss the risks, the challenges, and the opportunities that Large Language Models (LLMs) bring regarding factuality. We will then delve into our recent work on using LLMs for fact-checking, on detecting machine-generated text, and on fighting the ongoing misinformation pollution with LLMs. We will also discuss work on safeguarding LLMs, and the safety mechanisms we incorporated in Jais-chat, the world's best open Arabic-centric foundation and instruction-tuned LLM, based on our Do-Not-Answer dataset. Finally, we will present a number of LLM fact-checking tools recently developed at MBZUAI: (i) LM-Polygraph, a tool to predict an LLM's uncertainty in its output using cheap and fast uncertainty quantification techniques, (ii) Factcheck-Bench, a fine-grained evaluation benchmark and framework for fact-checking the output of LLMs, (iii) Loki, an open-source tool for fact-checking the output of LLMs, developed based on Factcheck-Bench and optimized for speed and quality, (iv) OpenFactCheck, a framework for fact-checking LLM output, for building customized fact-checking systems, and for benchmarking LLMs for factuality, and (v) LLM-DetectAIve, a tool for machine-generated text detection.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                10:10am
            </td>
            <td class="title">
                TBD
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://subha0009.github.io/">Subhabrata Dutta</a> (TU Darmstadt)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                TBD
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                10:50am
            </td>
            <td class="title-special">
                Coffee &amp; Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:00am
            </td>
            <td class="title">
                Auditing and Mitigating Biases in (compressed) Language Models
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://velcin.github.io/">Julien Velcin</a> (Université de Lyon)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                The size of language models plays a critical role in their ability to address complex tasks in NLP. However such big LMs can be hard to deploy on edge devices which leads to the need of compressing LLMs. Recent studies have shown that compressing pretrained models can significantly influence the way they deal with various biases, such as biases related to fairness and model calibration. In this talk, I will provide an overview of recent research conducted at the ERIC Lab as part of the <a target="_blank" href="https://www.anr-dike.fr/">DIKé project</a>. In particular, We will see how important quantization can lead to calibration errors and alter the model's confidence in its predictions. Additionnally, I will discuss ongoing work on the alignement of LLMs with moral values.
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                11:40am
            </td>
            <td class="title">
                TBD
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://www.telecom-paris.fr/gael-richard">Gaël Richard</a> (Télécom Paris)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                TBD
            </td>
        </tr>
    </table>

    <!--<table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                11:00am
            </td>
            <td class="title">
                This is a Plenary Talk!
            </td>
        </tr>
        <tr>
            <td class="speaker">
                Plenary Speaker
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Here&rsquo;s the abstract for the plenary talk! Notice again that the formatting of this time-block is a bit different that the rest of of the talks.
                Filler text: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vestibulum dignissim et est et euismod. Fusce et metus tempus, pellentesque ex at, convallis nulla. Ut fringilla commodo tincidunt. Fusce sed est eu massa placerat iaculis eu at mauris. Nullam ut mollis nisi, quis malesuada risus. Interdum et malesuada fames ac ante ipsum primis in faucibus. Nam ipsum tortor, suscipit non tincidunt vel, bibendum in libero. Nulla facilisi. Pellentesque vitae neque metus. Cras quis est pharetra, vestibulum nisl et, viverra ipsum. Etiam porta dignissim purus, quis tempor metus volutpat eu. Praesent pulvinar libero eget purus tincidunt finibus.
            </td>
        </tr>
    </table>-->

    <table>
        <tr>
            <td class="date" rowspan="2">
                12:20pm
            </td>
            <td class="title-special">
                Lunch
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                13:30pm
            </td>
            <td class="title">
                TBD 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://is.mpg.de/~bs">Bernhard Schölkopf</a> (Max Planck Institute for Intelligent Systems)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                TBD
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                14:10pm
            </td>
            <td class="title">
                Towards the Alignment of Geometric and Text Latent Spaces
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://www.lix.polytechnique.fr/~maks/">Maks Ovsjanikov</a> (École Polytechnique)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Recent works have shown that, when trained at scale, uni-modal 2D vision and text encoders converge to learned features that share remarkable structural properties, despite arising from different representations. However, the role of 3D encoders with respect to other modalities remains unexplored. Furthermore, existing 3D foundation models that leverage large datasets are typically trained with explicit alignment objectives with respect to frozen encoders from other representations. In this talk I will discuss some results on the alignment of representations obtained from uni-modal 3D encoders compared to text-based feature spaces. Specifically, I will show that it is possible to extract subspaces of the learned feature spaces that have common structure between geometry and text. This alignment also leads to improvement in downstream tasks, such as zero shot retrieval. Overall, this work helps to highlight both the shared and unique properties of 3D data compared to other representations.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                14:50pm
            </td>
            <td class="title-special">
                Coffee &amp; Tea Break
            </td>
        </tr>
        <tr>
            <td class="abstract">
                <!-- Kept for Spacing -->
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:00pm
            </td>
            <td class="title">
                TBD
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://ai.honu.io/">Alexandre Desfossez</a> (Kyutai)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                TBD
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                15:40pm
            </td>
            <td class="title">
                TBD 
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://keg.cs.tsinghua.edu.cn/jietang/">Jie Tang</a> (Tsinghua University)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                TBD
            </td>
        </tr>
    </table>

    <table id="PUTSPEAKERNAMEHERE">
        <tr>
            <td class="date" rowspan="3">
                16:20pm
            </td>
            <td class="title">
                What's not an Autoregressive LLM?
            </td>
        </tr>
        <tr>
            <td class="speaker">
                <a target="_blank" href="https://ikekonglp.github.io/">Linpeng Kong</a> (University of Hong Kong)
            </td>
        </tr>
        <tr>
            <td class="abstract">
                This talk explores alternatives to autoregressive Large Language Models (LLMs), with a particular focus on discrete diffusion models. The presentation covers recent advances in non-autoregressive approaches to text generation, reasoning, and planning tasks. Key developments discussed include Reparameterized Discrete Diffusion Models (RDMs), which show promising results in machine translation and error correction, and applications of discrete diffusion to complex reasoning tasks like countdown games, Sudoku, and chess. The talk also examines sequence-to-sequence text diffusion models, as well as the novel Diffusion of Thoughts (DoTs) framework for chain-of-thought reasoning. These non-autoregressive approaches demonstrate competitive performance while offering potential advantages in terms of parallel processing and flexible generation patterns compared to traditional autoregressive models.
            </td>
        </tr>
    </table>

    <table class="plenary">
        <tr>
            <td class="date" rowspan="3">
                18:00pm
            </td>
            <td class="title">
                Poster Session at MBZUAI France Lab
            </td>
        </tr>
        <tr>
            <td class="speaker">
                To present a poster, please fill out the <a href="https://forms.gle/susJHsShLfFixjMG8" target="_blank">Google form</a> for review.
            </td>
        </tr>
        <tr>
            <td class="abstract">
                Workshop participants are invited to join the poster session at MBZUAI France Lab.<br>
                Address: 42 Rue Notre Dame des Victoires, 75002 Paris
            </td>
        </tr>
    </table>

    <footer>
        &copy; MBZUAI France Lab
        &nbsp;|&nbsp; Design by <a href="https://github.com/mikepierce">Mike Pierce</a>
    </footer>

</body>
</html>

